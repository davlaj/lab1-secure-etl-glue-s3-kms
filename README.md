# Lab 1 â€“ Secure ETL Pipeline with AWS Glue, S3, IAM, KMS and QuickSight

## ğŸ§  Context

This lab simulates a real-world scenario where a healthcare company ("HealthPlus") needs to securely process and analyze sensitive medical data using AWS-native tools. The pipeline must respect data privacy, security, and regulatory best practices, while preparing the data for analytical dashboards.

---

## ğŸ¯ Objectives

- Ingest raw sensitive data stored in S3
- Clean and transform it with AWS Glue
- Secure storage using encryption at rest (KMS)
- Apply IAM policies following the principle of least privilege
- Log all operations for auditability
- Build a visual dashboard in Amazon QuickSight

---

## ğŸ§± Architecture

![Architecture Diagram](https://github.com/davlaj/lab1-secure-etl-glue-s3-kms/blob/main/architecture/lab1-secure-etl-glue-s3-kms.drawio.png?raw=true)

---

## ğŸ§° AWS Services Used

- **Amazon S3**: Raw and processed data storage
- **AWS KMS**: Encryption key for sensitive output
- **AWS IAM**: Fine-grained permissions and service roles
- **AWS Glue**: ETL pipeline (crawler + job)
- **AWS CloudTrail & CloudWatch**: Logging and auditing
- **Amazon QuickSight**: Final dashboard and reporting

---

## ğŸ§ª Lab Blocks

This lab is divided into short blocks.

### âœ… Block 1 â€” Environment Setup
- [x] Create S3 buckets (`raw`, `processed`)
- [x] Create a custom symmetric KMS key
- [x] Upload encrypted patient data (CSV) with SSE-KMS
- [x] Define IAM role for AWS Glue with least privilege
- [ ] Enable CloudTrail and configure audit log S3 bucket

### â³ Block 2 â€” ETL Pipeline
- [ ] Create Glue Crawler for raw dataset
- [ ] Create PySpark Glue Job for cleaning & transformation
- [ ] Write output to encrypted S3 bucket (`processed`)

### â³ Block 3 â€” Validation and Audit
- [ ] Check KMS encryption is applied on output files
- [ ] Validate Glue Catalog and schema
- [ ] Inspect logs in **CloudWatch Logs** (Glue Job runtime)
- [ ] Enable and inspect **CloudTrail** (S3 access, KMS usage, IAM activity)
- [ ] Set retention policy for CloudTrail + cost-efficient log storage

### â³ Block 4 â€” Visualization with QuickSight
- [ ] Connect QuickSight to processed dataset
- [ ] Create visuals (age, country, condition, map)
- [ ] Apply row-level access controls (if needed)

---

## ğŸ“ Notes & Logs

See [`logs/session_notes.md`](logs/session_notes.md) for detailed session steps and issues encountered.

---

## ğŸ“¸ Screenshots

See [`screenshots/`](screenshots/) for architecture, dashboard, and audit evidence.

---

## ğŸ’¸ Cost Protection & Monitoring

This project was conducted in a personal AWS account with all billing safety mechanisms enabled:

- âœ… **Budget Alerts**:
  - `Zero-Spend Budget`: alerts when costs exceed $0.01
  - `Monthly Budget`: $5/month soft limit with email alerts at 85% and 100%
  
- âœ… **Anomaly Detection Monitor**:
  - Name: `aws-lab-anomaly-monitor`
  - Monitors total monthly spend at the account level
  - Uses Amazon SNS for immediate alerting in case of spending spikes

- âœ… **Manual Cleanup Script**:
  - All lab resources are cleaned up with [`delete_all_lab1_resources.sh`](cli/delete_all_lab1_resources.sh)

These safeguards ensure full cost transparency and control throughout the lab process.

---

## ğŸ’¸ Security

This lab enforces production-grade security and cost governance:

- âœ… Budget alerts and cost anomaly detection are enabled
- âœ… KMS is used for encryption at rest on both raw and processed data buckets
- âœ… All sensitive data is encrypted upon upload with `--sse-kms`
- âœ… IAM roles and policies are auto-generated with strict least-privilege rules
- âœ… Keys are reused safely unless explicitly deleted

---

## ğŸ§  Author & Motivation

This project is part of a hands-on AWS portfolio to demonstrate secure cloud data engineering capabilities.  
Feel free to fork, improve, or suggest enhancements via issues or pull requests.
